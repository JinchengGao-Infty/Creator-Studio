# 任务：T1.5 实现 Tauri ↔ ai-engine 通信

## 任务目标

实现 Tauri 后端与 ai-engine 包之间的通信，让 AI 能够调用 Tool（文件操作）。

## 背景

- **T1.2 已完成**：Rust 文件操作模块在 `src-tauri/src/file_ops/`
- **T1.4 已完成**：ai-engine 包在 `packages/ai-engine/`

现在需要把它们连接起来。

## 架构设计

```
React 前端
    │
    │ Tauri IPC (invoke)
    ▼
Tauri 后端 (Rust)
    │
    │ 调用 ai-engine
    ▼
ai-engine (TypeScript/Bun)
    │
    │ 调用模型，返回 tool calls
    ▼
Tauri 后端 (Rust)
    │
    │ 执行 file_ops
    ▼
返回结果给 ai-engine
    │
    ▼
最终结果返回给前端
```

## 你需要做的

### 方案：在 Tauri 中直接调用 Bun 运行 ai-engine

由于 ai-engine 是 TypeScript 包，我们用 Bun 运行它，通过 stdin/stdout JSON 通信。

### 1. 创建 ai-engine CLI 入口

在 `packages/ai-engine/src/cli.ts` 创建命令行入口：

```typescript
#!/usr/bin/env bun

import { createEngine } from './index'
import type { ToolCallRequest, ToolCallResult, Message, ProviderConfig, ModelParameters } from './types'

// 从 stdin 读取 JSON 请求
// 格式：
// {
//   "type": "chat",
//   "provider": { ... },
//   "parameters": { ... },
//   "systemPrompt": "...",
//   "messages": [...],
// }

// 当需要执行 tool 时，输出到 stdout：
// { "type": "tool_call", "calls": [...] }

// 从 stdin 读取 tool 执行结果：
// { "type": "tool_result", "results": [...] }

// 最终输出：
// { "type": "done", "content": "..." }
// 或
// { "type": "error", "message": "..." }

async function main() {
  const engine = createEngine()
  
  // 读取初始请求
  const input = await readJsonFromStdin()
  
  if (input.type !== 'chat') {
    console.log(JSON.stringify({ type: 'error', message: 'Unknown request type' }))
    process.exit(1)
  }
  
  // 添加 provider
  engine.providerManager.addProvider(input.provider as ProviderConfig)
  
  // 运行 agent，使用回调处理 tool calls
  try {
    const result = await engine.agent.run(
      input.messages as Message[],
      {
        providerId: input.provider.id,
        parameters: input.parameters as ModelParameters,
        systemPrompt: input.systemPrompt,
        executeTools: async (calls: ToolCallRequest[]) => {
          // 输出 tool calls 请求
          console.log(JSON.stringify({ type: 'tool_call', calls }))
          
          // 等待 tool 执行结果
          const resultInput = await readJsonFromStdin()
          if (resultInput.type !== 'tool_result') {
            throw new Error('Expected tool_result')
          }
          return resultInput.results as ToolCallResult[]
        },
      }
    )
    
    console.log(JSON.stringify({ type: 'done', content: result.content }))
  } catch (error) {
    console.log(JSON.stringify({ type: 'error', message: String(error) }))
    process.exit(1)
  }
}

async function readJsonFromStdin(): Promise<any> {
  // 从 stdin 读取一行 JSON
  const reader = Bun.stdin.stream().getReader()
  let buffer = ''
  
  while (true) {
    const { done, value } = await reader.read()
    if (done) break
    
    buffer += new TextDecoder().decode(value)
    const newlineIndex = buffer.indexOf('\n')
    if (newlineIndex !== -1) {
      const line = buffer.slice(0, newlineIndex)
      reader.releaseLock()
      return JSON.parse(line)
    }
  }
  
  throw new Error('EOF before complete JSON')
}

main()
```

更新 `packages/ai-engine/package.json`，添加 bin：
```json
{
  "bin": {
    "ai-engine": "./src/cli.ts"
  }
}
```

### 2. 在 Tauri 中调用 ai-engine

创建 `src-tauri/src/ai_bridge.rs`：

```rust
use std::process::{Command, Stdio};
use std::io::{BufRead, BufReader, Write};
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};

use crate::file_ops::{read, write, append, list, search};

#[derive(Debug, Serialize, Deserialize)]
pub struct ChatRequest {
    pub provider: Value,
    pub parameters: Value,
    pub system_prompt: String,
    pub messages: Vec<Value>,
    pub project_dir: String,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ChatResponse {
    pub content: String,
}

pub fn run_chat(request: ChatRequest) -> Result<ChatResponse, String> {
    // 启动 bun 运行 ai-engine
    let ai_engine_path = std::env::current_dir()
        .map_err(|e| e.to_string())?
        .join("packages/ai-engine/src/cli.ts");
    
    let mut child = Command::new("bun")
        .arg("run")
        .arg(&ai_engine_path)
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::piped())
        .spawn()
        .map_err(|e| format!("Failed to spawn ai-engine: {}", e))?;
    
    let mut stdin = child.stdin.take().ok_or("Failed to get stdin")?;
    let stdout = child.stdout.take().ok_or("Failed to get stdout")?;
    let mut reader = BufReader::new(stdout);
    
    // 发送初始请求
    let init_request = json!({
        "type": "chat",
        "provider": request.provider,
        "parameters": request.parameters,
        "systemPrompt": request.system_prompt,
        "messages": request.messages,
    });
    
    writeln!(stdin, "{}", init_request.to_string())
        .map_err(|e| format!("Failed to write to stdin: {}", e))?;
    
    // 循环处理响应
    loop {
        let mut line = String::new();
        reader.read_line(&mut line)
            .map_err(|e| format!("Failed to read from stdout: {}", e))?;
        
        if line.is_empty() {
            return Err("Unexpected EOF".to_string());
        }
        
        let response: Value = serde_json::from_str(&line)
            .map_err(|e| format!("Failed to parse response: {}", e))?;
        
        match response["type"].as_str() {
            Some("done") => {
                let content = response["content"].as_str().unwrap_or("").to_string();
                return Ok(ChatResponse { content });
            }
            Some("error") => {
                let message = response["message"].as_str().unwrap_or("Unknown error");
                return Err(message.to_string());
            }
            Some("tool_call") => {
                // 执行 tool calls
                let calls = response["calls"].as_array()
                    .ok_or("Invalid tool_call format")?;
                
                let mut results = Vec::new();
                for call in calls {
                    let name = call["name"].as_str().unwrap_or("");
                    let args = &call["args"];
                    let id = call["id"].as_str().unwrap_or("");
                    
                    let result = execute_tool(&request.project_dir, name, args)?;
                    results.push(json!({
                        "id": id,
                        "result": result,
                    }));
                }
                
                // 发送 tool 执行结果
                let tool_result = json!({
                    "type": "tool_result",
                    "results": results,
                });
                writeln!(stdin, "{}", tool_result.to_string())
                    .map_err(|e| format!("Failed to write tool result: {}", e))?;
            }
            _ => {
                return Err(format!("Unknown response type: {}", line));
            }
        }
    }
}

fn execute_tool(project_dir: &str, name: &str, args: &Value) -> Result<String, String> {
    match name {
        "read" => {
            let path = args["path"].as_str().ok_or("Missing path")?;
            let offset = args["offset"].as_u64().map(|v| v as u32);
            let limit = args["limit"].as_u64().map(|v| v as u32);
            
            let params = read::ReadParams {
                path: path.to_string(),
                offset,
                limit,
            };
            let result = read::file_read(project_dir.to_string(), params)?;
            Ok(serde_json::to_string(&result).unwrap())
        }
        "write" => {
            let path = args["path"].as_str().ok_or("Missing path")?;
            let content = args["content"].as_str().ok_or("Missing content")?;
            
            let params = write::WriteParams {
                path: path.to_string(),
                content: content.to_string(),
            };
            write::file_write(project_dir.to_string(), params)?;
            Ok("File written successfully".to_string())
        }
        "append" => {
            let path = args["path"].as_str().ok_or("Missing path")?;
            let content = args["content"].as_str().ok_or("Missing content")?;
            
            let params = append::AppendParams {
                path: path.to_string(),
                content: content.to_string(),
            };
            append::file_append(project_dir.to_string(), params)?;
            Ok("Content appended successfully".to_string())
        }
        "list" => {
            let path = args["path"].as_str().map(|s| s.to_string());
            
            let params = list::ListParams { path };
            let result = list::file_list(project_dir.to_string(), params)?;
            Ok(serde_json::to_string(&result).unwrap())
        }
        "search" => {
            let query = args["query"].as_str().ok_or("Missing query")?;
            let path = args["path"].as_str().map(|s| s.to_string());
            
            let params = search::SearchParams {
                query: query.to_string(),
                path,
            };
            let result = search::file_search(project_dir.to_string(), params)?;
            Ok(serde_json::to_string(&result).unwrap())
        }
        _ => Err(format!("Unknown tool: {}", name)),
    }
}
```

### 3. 注册 Tauri Command

在 `src-tauri/src/lib.rs` 添加：

```rust
mod ai_bridge;

#[tauri::command]
async fn ai_chat(
    provider: serde_json::Value,
    parameters: serde_json::Value,
    system_prompt: String,
    messages: Vec<serde_json::Value>,
    project_dir: String,
) -> Result<String, String> {
    let request = ai_bridge::ChatRequest {
        provider,
        parameters,
        system_prompt,
        messages,
        project_dir,
    };
    
    let response = ai_bridge::run_chat(request)?;
    Ok(response.content)
}

// 在 run() 函数中注册
.invoke_handler(tauri::generate_handler![
    // ... 其他命令
    ai_chat,
])
```

### 4. 前端调用示例

在 React 中测试：

```typescript
import { invoke } from '@tauri-apps/api/core'

async function testAIChat() {
  const result = await invoke('ai_chat', {
    provider: {
      id: 'test',
      name: 'Test',
      baseURL: 'http://127.0.0.1:3002/geminicli/v1',
      apiKey: 'sk-xxx',
      models: ['gemini-3-pro-preview'],
      providerType: 'openai-compatible',
    },
    parameters: {
      model: 'gemini-3-pro-preview',
      temperature: 0.7,
      maxTokens: 2000,
    },
    systemPrompt: '你是一个写作助手。',
    messages: [
      { role: 'user', content: '读取 README.md 文件的内容' }
    ],
    projectDir: '/Users/link/Desktop/creatorai-v2',
  })
  
  console.log('AI Response:', result)
}
```

### 5. 测试验证

1. 确保 `npm run tauri dev` 能编译通过
2. 在前端调用 `ai_chat` 命令
3. 验证 AI 能调用 `read` tool 读取文件
4. 验证 AI 能调用 `write` 或 `append` tool 写入文件

## 参考

- 现有 Rust 文件操作：`src-tauri/src/file_ops/`
- 现有 ai-engine：`packages/ai-engine/src/`
- Tauri Command 文档：https://tauri.app/develop/calling-rust/

## 输出

- `packages/ai-engine/src/cli.ts` CLI 入口
- `src-tauri/src/ai_bridge.rs` Tauri 与 ai-engine 桥接
- `ai_chat` Tauri command 注册
- 能通过前端调用 AI 并执行 Tool

## 完成标记

完成后在输出末尾标记：`[TASK_COMPLETE]`

如果遇到问题无法解决，标记：`[TASK_FAILED: 原因]`
